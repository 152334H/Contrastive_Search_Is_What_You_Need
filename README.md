# Contrastive Search Might Be All You Need
**Authors**: Yixuan Su and Nigel Collier

This repository contains code other related resources of our paper ["Contrastive Search Might Be All You Need"]().

****
If you find our paper and resources useful, please kindly leave a star and cite our papers. Thanks!

```bibtex
@article{su2022contrastive,
  title={A Contrastive Framework for Neural Text Generation},
  author={Su, Yixuan and Lan, Tian and Wang, Yan and Yogatama, Dani and Kong, Lingpeng and Collier, Nigel},
  journal={arXiv preprint arXiv:2202.06417},
  year={2022}
}
```

****

### News:
* [2022/10/xx]  is publicly released!

****

<span id='all_catelogue'/>

### Catalogue:
* <a href='#introduction'>1. Introduction</a>
* <a href='#reproduce_examples'>2. Reproducing Examples Provided in the Paper</a>
    * <a href='#use_transformers'>2.1. Using Huggingface Transformers</a>
    * <a href='#use_simctg'>2.2. Using SimCTG Package</a>
        * <a href='#install_simctg'>2.2.1. Install SimCTG Package</a>
        * <a href='#simctg_table_1'>2.2.2. Example in Table 1</a>
        * <a href='#simctg_table_8'>2.2.3. Example in Table 8 at Appendix A</a>
    

****

<span id='introduction'/>

#### 1. Introduction: <a href='#all_catelogue'>[Back to Top]</a>

****


<span id='reproduce_examples'/>


#### 2. Reproducing Examples Provided in the Paper: <a href='#all_catelogue'>[Back to Top]</a>
In this section, we demonstrate two ways of reproducing the examples generated by contrastive search provided in our paper.

<span id='use_transformers'/>

##### 2.1. Using Huggingface Transformers: <a href='#all_catelogue'>[Back to Top]</a>

To be completed.

<span id='use_simctg'/>

##### 2.2. Using SimCTG Package: <a href='#all_catelogue'>[Back to Top]</a>

<span id='install_simctg'/>

###### 2.2.1. Install SimCTG Package: <a href='#all_catelogue'>[Back to Top]</a>

To install the package, please run the following command:

```yaml
pip install simctg --upgrade
```

<span id='simctg_table_1'/>

###### 2.2.2. Example in Table 1: <a href='#all_catelogue'>[Back to Top]</a>

To reproduce our example provided in Table 1, please run the following command:
```python
# load the LMs
import torch
from simctg.simctggpt import SimCTGGPT
model_name = r'gpt2-large'
model = SimCTGGPT(model_name)
model.eval()
tokenizer = model.tokenizer
eos_token_id = tokenizer.eos_token_id

# prepare the prefix
prefix_text = r"Kobe Bryant is"
tokens = tokenizer.tokenize(prefix_text)
input_ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = torch.LongTensor(input_ids).view(1,-1)

# generate the result with contrastive search
beam_width, alpha, decoding_len = 4, 0.6, 256
output = model.fast_contrastive_search(input_ids=input_ids, beam_width=beam_width, 
                                       alpha=alpha, decoding_len=decoding_len,
                                      end_of_sequence_token_id = eos_token_id, early_stop = True) 
print("Output:\n" + 100 * '-')
print(tokenizer.decode(output))
print("" + 100 * '-')
```

<details>
<summary><b>Model Output: [click to expand]</b></summary>
  
```
Output:
----------------------------------------------------------------------------------------------------
Kobe Bryant is the best player in the world.

I know this is a bold statement to make, but it's true. He may have won a lot of games, but his
impact on the game is immeasurable. Kobe is one of the most popular players in the world, and
that's no small feat when you consider how many people play video games, watch sports, listen
to music, and have social media accounts.

Kobe has made a career out of being a role model for young people, and he does an amazing job
of that every time he steps on the court. His career stats are impressive, but what makes him
stand out is the way he goes about his business. When he's on the court, he's the center of
attention, and it's easy to see why.

The Lakers' All-Star point guard wears a smile on his face like no other. He's always in the
right place at the right time, making the right play at the right time, and doing the right
thing in the right way. He's not afraid to get his hands dirty, and he never shies away from
a physical confrontation.

Kobe's personality is something that can't be taught, and it's a big reason why...
----------------------------------------------------------------------------------------------------
```
</details>




<span id='simctg_table_8'/>

###### 2.2.3. Example in Table 8 at Appendix A: <a href='#all_catelogue'>[Back to Top]</a>

To reproduce our example provided in Table 8 at Appendix A, please run the following command:
```python
# load the LMs
import torch
from simctg.simctggpt import SimCTGGPT
model_name = r'gpt2-large'
model = SimCTGGPT(model_name)
model.eval()
tokenizer = model.tokenizer
eos_token_id = tokenizer.eos_token_id

# prepare the prefix
prefix_text = r"DeepMind Company is"
tokens = tokenizer.tokenize(prefix_text)
input_ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = torch.LongTensor(input_ids).view(1,-1)

# generate the result with contrastive search
beam_width, alpha, decoding_len = 4, 0.6, 512
output = model.fast_contrastive_search(input_ids=input_ids, beam_width=beam_width, 
                                       alpha=alpha, decoding_len=decoding_len,
                                      end_of_sequence_token_id = eos_token_id, early_stop = True) 
print("Output:\n" + 100 * '-')
print(tokenizer.decode(output))
print("" + 100 * '-')
```

<details>
<summary><b>Model Output: [click to expand]</b></summary>
  
```
Output:
----------------------------------------------------------------------------------------------------  
DeepMind Company is a leader in artificial intelligence (AI). We have a long history of working
with companies such as Google, Facebook, Amazon, and Microsoft to build products that improve
people's lives, and today we are excited to announce that DeepMind's AlphaGo program has won the
game of Go, becoming the first program to defeat a professional Go player.

The victory is a testament to the power of deep learning, and to the incredible work of our
research team, which has been at the forefront of AI research for the past five years. AlphaGo
is one of the most advanced Go programs ever created, and its performance is an important step
towards the goal of human-level AI.

"This is the culmination of a decade of hard work," said Andy Ng, co-founder and CTO of DeepMind.
"We are thrilled to have achieved this milestone and look forward to continuing to develop AI that
can be used in a wide range of applications and to help people live better lives."

DeepMind's work on Go began in 2010, when it began to train a neural network to play Go using
millions of games played by top Go players around the world. Since then, the team has refined the
algorithm, adding more and more layers of reinforcement learning to make it better at recognizing
patterns and making decisions based on those patterns. In the past year and a half, the team has
made significant progress in the game, winning a record-tying 13 games in a row to move into the
top four of the world rankings.

"The game of Go is a complex game in which players have to be very careful not to overextend their
territory, and this is something that we have been able to improve over and over again," said
Dr. Demis Hassabis, co-founder and Chief Scientific Officer of DeepMind. "We are very proud of our
team's work, and we hope that it will inspire others to take the next step in their research and
apply the same techniques to other problems."

In addition to the win in Go, DeepMind has also developed an AI system that can learn to play a
number of different games, including poker, Go, and chess. This AI system, called Tarsier, was
developed in partnership with Carnegie Mellon University and the University of California, 
Berkeley, and is being used to teach computer vision and machine learning to identify objects in
images and recognize speech in natural language. Tarsier has been trained to play the game of Go
and other games on a number of different platforms...
----------------------------------------------------------------------------------------------------
```
</details>

